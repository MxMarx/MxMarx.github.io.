# Results - Differential Expression

To compare lexicons for male and female characters across all authors, I used DESeq2 to compare word frequencies across character gender. This process is computationally intensive, so I only included the 10,000 most frequent words, and the 3000 character with the highest read depth (the entire dataset includes 25,000 characters across 6000 books). Result are visualized in an interactive plot (fig \@ref(fig:volcanoPlotCharacter)). Differentially expressed words for female (table \@ref(fig:femaleCharTable)) and male (table \@ref(fig:maleCharTable)) characters are included in the supplemental data. 

```{r volcanoPlotCharacter, fig.cap='Differential word frequency by character gender', out.width='100%'}
data <- read.csv("C:/Users/Russell/OneDrive - UW/Linguistics/R/gender_M_vs_F_char.csv")
p <- ggplot(data = data, aes(x = log2(baseMean * 1e6), y = log2FoldChange, text=sprintf("%s</br></br>log2FoldChange: %.3g</br>FDR: %.3g",X,log2FoldChange,padj), colour = padj)) +
  geom_point(alpha = 0.4) +  
  scale_color_gradient(low="red", high="blue", limits=c(0,.2), trans=scales::pseudo_log_trans(.000001), breaks=c(0,.001,.01,.05,.2)) +
  labs(y = "log2(fold change)", x="log2(word count)", color="False discovery rate") + 
  theme(panel.grid.major=element_blank(), panel.grid.minor=element_blank(), panel.backgroun=element_blank(), axis.line=element_line(colour="black")) 
p <- ggplotly(p, tooltip = c("text")) %>% toWebGL()
p
```

Next, I compared lexicons for male and female authors (fig \@ref(fig:volcanoPlotAuthor)). A subjective assessment of the data suggests that these differences largely are due to genre. Differentially expressed words are included in supplemental data (tables \@ref(fig:femaleAuthTable) and \@ref(fig:maleAuthTable) ).

```{r volcanoPlotAuthor, fig.cap='Differential word frequency by author gender', out.width='100%'}
data <- read.csv("C:/Users/Russell/OneDrive - UW/Linguistics/R/gender_M_vs_F.csv")
p <- ggplot(data = data, aes(x = log2(baseMean * 1e6), y = log2FoldChange, text=sprintf("%s</br></br>log2FoldChange: %.3g</br>FDR: %.3g",X,log2FoldChange,padj), colour = padj)) +
  geom_point(alpha = 0.4) +  
  scale_color_gradient(low="red", high="blue", limits=c(0,.2), trans=scales::pseudo_log_trans(.000001), breaks=c(0,.001,.01,.05,.2)) +
  labs(y = "log2(fold change)", x="log2(word count)", color="False discovery rate") + 
  theme(panel.grid.major=element_blank(), panel.grid.minor=element_blank(), panel.backgroun=element_blank(), axis.line=element_line(colour="black")) 
p <- ggplotly(p, tooltip = c("text")) %>% toWebGL()
p
```

Words that are more frequently associated with male characters are also more frequently used by male authors (fig \@ref(fig:CharAuthCorr)). The is likely a consequence of male authors more frequently writing male characters (fig \ref(fig:characterCounts)). I havenâ€™t figured out the best way to control for this difference. I might try weighting word frequency by character gender frequency.

```{r CharAuthCorr, fig.cap='Correlation between word frequency across character and author gender', out.width='100%'}
data <- read.csv("C:/Users/Russell/OneDrive - UW/Linguistics/R/charAuthJoined.csv")
data$min = rowMeans(data[c('padj_character','padj_author')], na.rm = T)
p <- ggplot(data = data, aes(x = log2FoldChange_character, y = log2FoldChange_author, color=min, text=Word)) +
  geom_point(alpha = 0.4) +  
  geom_hline(yintercept=0) +
  geom_vline(xintercept=0) +
  scale_color_gradient(low="red", high="blue", limits=c(0,.2), trans=scales::pseudo_log_trans(.000001), breaks=c(0,.001,.01,.05,.2)) +
  labs(y = "log2(fold change - author)", x="log2(fold change - character)", color="False discovery rate") + 
  theme(panel.grid.major=element_blank(), panel.grid.minor=element_blank(), panel.backgroun=element_blank(), axis.line=element_line(colour="black"), ) 
p <- ggplotly(p, tooltip = c("text")) %>% toWebGL()
p
```


Next, I trained an ensemble learner to classify characters (table \@ref(tab:charBoWClass)) and authors (table \@ref(tab:authBoWClass)) by gender using DESeq2 normalized word counts. This model classified author gender with disturbing accuracy. A bad interpretation would ignore variables such as genre. Goodreads.com tags are probably rather biased by author gender. Genre tags alone are only slightly less accurate at predicting author gender than the text (table \@ref(tab:tagsAuthConfusion)).

An alternative method might be to adapt another technique from single-cell RNA-sequencing. I might be able to position books on a manifold in *genre-space*, and examine how author genders are distributed along the manifold. 

```{r authBoWClass, fig.cap="Predicted author gender using bag of words."}
DT = data.frame(TM=c(1522,292), TF=c(298,1736))
row.names(DT) <- c("True Male","True Female")
knitr::kable(DT, col.names = c("Predicted Male","Predicted Female"), caption = 'predicted author gender using bag of words.') %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>%
  column_spec(1, bold = T)
```

```{r charBoWClass, fig.cap="Predicted character gender using bag of words."}
# F1 score: 84.6%
DT = data.frame(TM=c(4262,806), TF=c(738,4194))
row.names(DT) <- c("True Male","True Female")
knitr::kable(DT, col.names = c("Predicted Male","Predicted Female"), caption = 'Predicted character gender using bag of words.') %>%
  kable_styling(bootstrap_options = "striped", full_width = F) %>%
  column_spec(1, bold = T)
```







