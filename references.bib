@article{Finlay2017,
author = {Finlay, Toby},
file = {:C$\backslash$:/Users/Russell/OneDrive - UW/Documents/Mendeley Desktop/Finlay - 2017 - Non-Binary Performativity A Trans-Positive Account of Judith Butler ' s Queer Theory.pdf:pdf},
journal = {Laurier Undergraduate Journal of the Arts},
mendeley-groups = {Linguistics},
pages = {10--25},
title = {{Non-Binary Performativity: A Trans-Positive Account of Judith Butler' s Queer Theory Non-Binary Performativity: A Trans-Positive Account of Judith Butler's Queer Theory}},
url = {http://scholars.wlu.ca/luja},
volume = {4},
year = {2017}
}

@misc{goodbooks-10k,
    author       = {Zygmunt ZajÄ…c},
    title        = {{goodbooks-10k}},
    month        = Oct,
    year         = 2018,
    url          = {https://github.com/zygmuntz/goodbooks-10k}
    }

@misc{NeuralCoref,
    author       = {J Chaumond},
    title        = {NeuralCoref 4.0: Coreference Resolution in spaCy with Neural Networks.},
    month        = Dec,
    year         = 2019,
    url          = {https://github.com/huggingface/neuralcoref}
    }
    
@unpublished{spacy2,
    AUTHOR = {Honnibal, Matthew and Montani, Ines},
    TITLE  = {{spaCy 2}: Natural language understanding with {B}loom embeddings, convolutional neural networks and incremental parsing},
    YEAR   = {2017},
    Note   = {To appear}
}


@misc{SocialSecurity,
    author       = {{Social Security Administration}},
    title        = {Baby Names from Social Security Card Applications - National Data},
    month        = Nov,
    year         = 2019,
    url          = {https://catalog.data.gov/dataset/baby-names-from-social-security-card-applications-national-level-data}
    }
    
    
@article{Lee2016,
author = {Lee, J},
journal = {The Neuroethics Blog},
mendeley-groups = {Linguistics},
title = {{Embodied Cognition: What it means to "Throw like a Girl"}},
url = {http://www.theneuroethicsblog.com/2016/09/embodied-cognition-what-it-means-to.html},
year = {2016}
}

@article{Koolen2017,
abstract = {Stylometric and text categorization results show that author gender can be discerned in texts with relatively high accuracy. How-ever, it is difficult to explain what gives rise to these results and there are many possible confounding factors, such as the domain, genre, and target audience of a text. More fundamentally, such classification efforts risk invoking stereotyping and essential-ism. We explore this issue in two datasets of Dutch literary novels, using commonly used descriptive (LIWC, topic modeling) and predictive (machine learning) methods. Our results show the importance of con-trolling for variables in the corpus and we argue for taking care not to overgeneralize from the results.},
author = {Koolen, Corina and van Cranenburgh, Andreas},
doi = {10.18653/v1/w17-1602},
file = {:C$\backslash$:/Users/Russell/OneDrive - UW/Documents/Mendeley Desktop/Koolen, van Cranenburgh - 2017 - These are not the Stereotypes You are Looking For Bias and Fairness in Authorial Gender Attribution.pdf:pdf},
mendeley-groups = {Linguistics},
number = {2011},
pages = {12--22},
title = {{These are not the Stereotypes You are Looking For: Bias and Fairness in Authorial Gender Attribution}},
year = {2017}
}

  @Article{DESeq2,
    title = {Moderated estimation of fold change and dispersion for RNA-seq data with DESeq2},
    author = {Michael I. Love and Wolfgang Huber and Simon Anders},
    year = {2014},
    journal = {Genome Biology},
    doi = {10.1186/s13059-014-0550-8},
    volume = {15},
    issue = {12},
    pages = {550},
  }


    
@article{Thelwall2019,
abstract = {There are known gender differences in book preferences in terms of both genre and author gender but their extent and causes are not well understood. It is unclear whether reader preferences for author genders occur within any or all genres and whether readers evaluate books differently based on author genders within specific genres. This article exploits a major source of informal book reviews, the Goodreads.com website, to assess the influence of reader and author genders on book evaluations within genres. It uses a quantitative analysis of 201,560 books and their reviews, focusing on the top 50 user-specified genres. The results show strong gender differences in the ratings given by reviewers to books within genres, such as female reviewers rating contemporary romance more highly, with males preferring short stories. For most common book genres, reviewers give higher ratings to books authored by their own gender, confirming that gender bias is not confined to the literary elite. The main exception is the comic book, for which male reviewers prefer female authors, despite their scarcity. A word frequency analysis suggested that authors wrote, and reviewers valued, gendered aspects of books within a genre. For example, relationships and romance were disproportionately mentioned by women in mystery and fantasy novels. These results show that, perhaps for the first time, it is possible to get large-scale evidence about the reception of books by typical readers, if they post reviews online.},
author = {Thelwall, Mike},
doi = {10.1177/0961000617709061},
file = {:C$\backslash$:/Users/Russell/OneDrive - UW/Documents/Mendeley Desktop/Thelwall - 2019 - Reader and author gender and genre in Goodreads.pdf:pdf},
issn = {17416477},
journal = {Journal of Librarianship and Information Science},
keywords = {Book reviews,Goodreads,social web},
mendeley-groups = {Linguistics},
number = {2},
pages = {403--430},
title = {{Reader and author gender and genre in Goodreads}},
volume = {51},
year = {2019}
}


@inproceedings{Fast2016,
abstract = {Human language is colored by a broad range of topics, but existing text analysis tools only focus on a small number of them. We present Empath, a tool that can generate and validate new lexical categories on demand from a small set of seed terms (like "bleed" and "punch" to generate the category violence). Empath draws connotations between words and phrases by deep learning a neural embedding across more than 1.8 billion words of modern fiction. Given a small set of seed words that characterize a category, Empath uses its neural embedding to discover new related terms, then validates the category with a crowd-powered filter. Empath also analyzes text across 200 built-in, pre-validated categories we have generated from common topics in our web dataset, like neglect, government, and social media. We show that Empath's data-driven, human validated categories are highly correlated (r=0.906) with similar categories in LIWC.},
address = {New York, New York, USA},
archivePrefix = {arXiv},
arxivId = {1602.06979},
author = {Fast, Ethan and Chen, Binbin and Bernstein, Michael S.},
booktitle = {Conference on Human Factors in Computing Systems - Proceedings},
doi = {10.1145/2858036.2858535},
eprint = {1602.06979},
file = {:C$\backslash$:/Users/Russell/OneDrive - UW/Documents/Mendeley Desktop/Fast, Chen, Bernstein - 2016 - Empath Understanding topic signals in large-scale text.pdf:pdf},
isbn = {9781450333627},
issn = {1046-171X},
keywords = {Computational social science,Fiction,Social computing},
mendeley-groups = {Linguistics},
month = {mar},
number = {1},
pages = {4647--4657},
publisher = {ACM Press},
title = {{Empath: Understanding topic signals in large-scale text}},
url = {https://www.tandfonline.com/doi/full/10.1080/1046171X.1983.12034166 http://dl.acm.org/citation.cfm?doid=2858036.2858535},
volume = {11},
year = {2016}
}
